<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Logistic Regression | Stats For You</title>
  <meta name="description" content="<p>This book provides an introduction to various topics in statistics and
probability.</p>" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Logistic Regression | Stats For You" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This book provides an introduction to various topics in statistics and
probability.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Logistic Regression | Stats For You" />
  
  <meta name="twitter:description" content="<p>This book provides an introduction to various topics in statistics and
probability.</p>" />
  

<meta name="author" content="Frederick De Baene" />


<meta name="date" content="2026-01-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-models-and-deviance.html"/>
<link rel="next" href="missingness.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stats For You</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a></li>
<li class="chapter" data-level="2" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html"><i class="fa fa-check"></i><b>2</b> Logistic Models and Deviance</a>
<ul>
<li class="chapter" data-level="2.1" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#models"><i class="fa fa-check"></i><b>2.1</b> Models</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#proposed-model"><i class="fa fa-check"></i><b>2.1.1</b> Proposed Model</a></li>
<li class="chapter" data-level="2.1.2" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#null-model"><i class="fa fa-check"></i><b>2.1.2</b> Null Model</a></li>
<li class="chapter" data-level="2.1.3" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#saturated-model"><i class="fa fa-check"></i><b>2.1.3</b> Saturated Model</a></li>
<li class="chapter" data-level="2.1.4" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#models-and-deviance"><i class="fa fa-check"></i><b>2.1.4</b> Models and Deviance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#likelihood-and-log-likelihood"><i class="fa fa-check"></i><b>2.2</b> Likelihood and Log-Likelihood</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#proposed-model-1"><i class="fa fa-check"></i><b>2.2.1</b> Proposed Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#null-model-1"><i class="fa fa-check"></i><b>2.2.2</b> Null Model</a></li>
<li class="chapter" data-level="2.2.3" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#saturated-model-1"><i class="fa fa-check"></i><b>2.2.3</b> Saturated Model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="logistic-models-and-deviance.html"><a href="logistic-models-and-deviance.html#deviance"><i class="fa fa-check"></i><b>2.3</b> Deviance</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>3</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinary-logistic-regression"><i class="fa fa-check"></i><b>3.1</b> Ordinary Logistic Regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#context"><i class="fa fa-check"></i><b>3.1.1</b> Context</a></li>
<li class="chapter" data-level="3.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#model-fitting"><i class="fa fa-check"></i><b>3.1.2</b> Model Fitting</a></li>
<li class="chapter" data-level="3.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation"><i class="fa fa-check"></i><b>3.1.3</b> Interpretation</a></li>
<li class="chapter" data-level="3.1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.1.4</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#conditional-logistic-regression"><i class="fa fa-check"></i><b>3.2</b> Conditional Logistic Regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#definition"><i class="fa fa-check"></i><b>3.2.1</b> Definition</a></li>
<li class="chapter" data-level="3.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#probability"><i class="fa fa-check"></i><b>3.2.2</b> Probability</a></li>
<li class="chapter" data-level="3.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#conditional-probability"><i class="fa fa-check"></i><b>3.2.3</b> Conditional Probability</a></li>
<li class="chapter" data-level="3.2.4" data-path="logistic-regression.html"><a href="logistic-regression.html#probability-1"><i class="fa fa-check"></i><b>3.2.4</b> Probability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="missingness.html"><a href="missingness.html"><i class="fa fa-check"></i><b>4</b> Missingness</a>
<ul>
<li class="chapter" data-level="4.1" data-path="missingness.html"><a href="missingness.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="missingness.html"><a href="missingness.html#missingess-patterns"><i class="fa fa-check"></i><b>4.2</b> Missingess Patterns</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="missingness.html"><a href="missingness.html#simulation-setup"><i class="fa fa-check"></i><b>4.2.1</b> Simulation Setup</a></li>
<li class="chapter" data-level="4.2.2" data-path="missingness.html"><a href="missingness.html#missingness-completely-at-random"><i class="fa fa-check"></i><b>4.2.2</b> Missingness Completely at Random</a></li>
<li class="chapter" data-level="4.2.3" data-path="missingness.html"><a href="missingness.html#missingness-at-random"><i class="fa fa-check"></i><b>4.2.3</b> Missingness at Random</a></li>
<li class="chapter" data-level="4.2.4" data-path="missingness.html"><a href="missingness.html#missingness-not-at-random"><i class="fa fa-check"></i><b>4.2.4</b> Missingness Not at Random</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html"><i class="fa fa-check"></i><b>5</b> Relationships and Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#relationships"><i class="fa fa-check"></i><b>5.1</b> Relationships</a></li>
<li class="chapter" data-level="5.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#pearson-correlation-coefficient"><i class="fa fa-check"></i><b>5.2</b> Pearson Correlation Coefficient</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#calculating-coefficient"><i class="fa fa-check"></i><b>5.2.1</b> Calculating Coefficient</a></li>
<li class="chapter" data-level="5.2.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.2.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.2.3" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#no-relationship"><i class="fa fa-check"></i><b>5.2.3</b> No Relationship</a></li>
<li class="chapter" data-level="5.2.4" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#orange-dataset"><i class="fa fa-check"></i><b>5.2.4</b> Orange Dataset</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#spearman-rank-correlation"><i class="fa fa-check"></i><b>5.3</b> Spearman Rank Correlation</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stats For You</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Logistic Regression<a href="logistic-regression.html#logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, we explore logistic regression. This type of model can be used
to estimate the probability of a particular event occurring or not. This means
that the outcome must be binary, i.e., there are only two possible outcomes.</p>
<div id="ordinary-logistic-regression" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Ordinary Logistic Regression<a href="logistic-regression.html#ordinary-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The most well-known logistic regression is ordinary logistic regression. In a
next chapter, we will discuss conditional logistic regression.</p>
<div id="context" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Context<a href="logistic-regression.html#context" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we randomly select a patient and assess his/her survival status. The
outcome of this random experiment is captured using the random variable <span class="math inline">\(Y\)</span>. The
random variable <span class="math inline">\(Y\)</span> can take on one of only two possible outcomes, therefore it
is a binary random variable (or Bernoulli random variable).</p>
<p>If we repeat this process for <span class="math inline">\(n\)</span> patients, then we have <span class="math inline">\(n\)</span> random variables,
i.e., <span class="math inline">\(Y_i\)</span> for <span class="math inline">\(i = 1, 2, ..., n\)</span>. Assume we observe the following:</p>
<pre><code>##   i Y
## 1 1 1
## 2 2 0
## 3 3 0
## 4 4 1
## 5 5 0</code></pre>
<p>We have <span class="math inline">\(n = 5\)</span> patients. For each patient, the outcome <span class="math inline">\(Y_i\)</span> is observed.
Because the variable <span class="math inline">\(Y_i\)</span> is a Bernoulli random variable, its probability
distribution is defined by the following probability mass function:</p>
<p><span class="math display">\[
f_i (Y_i) = \pi_i^{Y_i} \cdot (1 - \pi_i)^{(1 - Y_i)}
\]</span></p>
<p>We again observe the previously observed outcomes but recognize that, for each
patient, the outcome is drawn randomly from a Bernoulli distribution defined by
<span class="math inline">\(\pi_i\)</span>:</p>
<pre><code>##   i Y  P.Y...1.
## 1 1 1 0.2875775
## 2 2 0 0.7883051
## 3 3 0 0.4089769
## 4 4 1 0.8830174
## 5 5 0 0.9404673</code></pre>
<p>We can also visualize the five Bernoulli distributions for each of the patients.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="logistic-regression.html#cb19-1" tabindex="-1"></a><span class="cf">for</span> (idx <span class="cf">in</span> <span class="fu">seq_along</span>(probs)) {</span>
<span id="cb19-2"><a href="logistic-regression.html#cb19-2" tabindex="-1"></a>  </span>
<span id="cb19-3"><a href="logistic-regression.html#cb19-3" tabindex="-1"></a>  prob <span class="ot">&lt;-</span> probs[idx]</span>
<span id="cb19-4"><a href="logistic-regression.html#cb19-4" tabindex="-1"></a>  <span class="fu">plot</span>(</span>
<span id="cb19-5"><a href="logistic-regression.html#cb19-5" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb19-6"><a href="logistic-regression.html#cb19-6" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">1</span> <span class="sc">-</span> prob, prob),</span>
<span id="cb19-7"><a href="logistic-regression.html#cb19-7" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Y&quot;</span>,</span>
<span id="cb19-8"><a href="logistic-regression.html#cb19-8" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Probability&quot;</span>,</span>
<span id="cb19-9"><a href="logistic-regression.html#cb19-9" tabindex="-1"></a>    <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Patient 0&quot;</span>, idx),</span>
<span id="cb19-10"><a href="logistic-regression.html#cb19-10" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb19-11"><a href="logistic-regression.html#cb19-11" tabindex="-1"></a>    <span class="at">col =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb19-12"><a href="logistic-regression.html#cb19-12" tabindex="-1"></a>    <span class="at">pch =</span> <span class="dv">16</span></span>
<span id="cb19-13"><a href="logistic-regression.html#cb19-13" tabindex="-1"></a>  )</span>
<span id="cb19-14"><a href="logistic-regression.html#cb19-14" tabindex="-1"></a>  </span>
<span id="cb19-15"><a href="logistic-regression.html#cb19-15" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-21-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-21-2.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-21-3.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-21-4.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-21-5.png" width="672" /></p>
</div>
<div id="model-fitting" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Model Fitting<a href="logistic-regression.html#model-fitting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We use the <strong>heart</strong> dataset and denote the outcome in the heart dataset with
the variable <span class="math inline">\(Y\)</span>, with <span class="math inline">\(Y = 1\)</span> if the patient has a heart disease and <span class="math inline">\(Y = 0\)</span>
otherwise.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="logistic-regression.html#cb20-1" tabindex="-1"></a>heart<span class="sc">$</span>Y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(heart<span class="sc">$</span>HeartDisease)</span></code></pre></div>
<p>Prior to fitting a model, we cast the categorical variables to factors.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="logistic-regression.html#cb21-1" tabindex="-1"></a>heart<span class="sc">$</span>ChestPainType <span class="ot">&lt;-</span> <span class="fu">factor</span>(</span>
<span id="cb21-2"><a href="logistic-regression.html#cb21-2" tabindex="-1"></a>  <span class="at">x =</span> heart<span class="sc">$</span>ChestPainType, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;ASY&quot;</span>, <span class="st">&quot;NAP&quot;</span>, <span class="st">&quot;TA&quot;</span>, <span class="st">&quot;ATA&quot;</span>)</span>
<span id="cb21-3"><a href="logistic-regression.html#cb21-3" tabindex="-1"></a>)</span>
<span id="cb21-4"><a href="logistic-regression.html#cb21-4" tabindex="-1"></a>heart<span class="sc">$</span>Sex <span class="ot">&lt;-</span> <span class="fu">factor</span>(</span>
<span id="cb21-5"><a href="logistic-regression.html#cb21-5" tabindex="-1"></a>  <span class="at">x =</span> heart<span class="sc">$</span>Sex, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>)</span>
<span id="cb21-6"><a href="logistic-regression.html#cb21-6" tabindex="-1"></a>)</span></code></pre></div>
<p>We fit the following model to the data:</p>
<p><span class="math display">\[
\mathbb{E} [Y_i] = \beta_0 + \beta_1 \cdot X_{age} + \beta_2 \cdot X_{male}
\]</span></p>
<p>with <span class="math inline">\(X_{age}\)</span> the age and <span class="math inline">\(X_{male} = 1\)</span> if the person is male and
<span class="math inline">\(X_{male} = 0\)</span> otherwise. The model contains three parameters, i.e., <span class="math inline">\(\beta_0\)</span>,
<span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\beta_2\)</span>. We call <strong>glm()</strong> as follows to fit the model:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="logistic-regression.html#cb22-1" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb22-2"><a href="logistic-regression.html#cb22-2" tabindex="-1"></a>  <span class="at">formula =</span> <span class="st">&quot;HeartDisease ~ Age + Sex&quot;</span>,</span>
<span id="cb22-3"><a href="logistic-regression.html#cb22-3" tabindex="-1"></a>  <span class="at">data =</span> heart,</span>
<span id="cb22-4"><a href="logistic-regression.html#cb22-4" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">&quot;logit&quot;</span>)</span>
<span id="cb22-5"><a href="logistic-regression.html#cb22-5" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = &quot;HeartDisease ~ Age + Sex&quot;, family = binomial(link = &quot;logit&quot;), 
##     data = heart)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -4.634893   0.481185  -9.632  &lt; 2e-16 ***
## Age          0.066531   0.008165   8.148 3.69e-16 ***
## SexM         1.641195   0.189345   8.668  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1262.1  on 917  degrees of freedom
## Residual deviance: 1101.6  on 915  degrees of freedom
## AIC: 1107.6
## 
## Number of Fisher Scoring iterations: 4</code></pre>
</div>
<div id="interpretation" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Interpretation<a href="logistic-regression.html#interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Us the parameter estimates, we have the following model:</p>
<p><span class="math display">\[
log(\frac{\pi_i}{1 - \pi_i}) = -4.634893 + 0.066531 \cdot X_{age} + 1.641195 \cdot X_{male}
\]</span></p>
<p>Assume that person <span class="math inline">\(i\)</span> is a 40-year-old woman. The probability of person <span class="math inline">\(i\)</span>
having a heart disease is the following:</p>
<p><span class="math display">\[
\begin{align}
log(\frac{\pi_i}{1 - \pi_i})
  &amp;= -4.634893 + 0.066531 \cdot 40 + 1.641195 \cdot 0 \\
  &amp;= -4.634893 + 0.066531 \cdot 40 \\
  &amp;= -1.973653
\end{align}
\]</span></p>
<p>The estimated logit equals -1.973653. The estimated odds of a 40-year-old woman
having a heart disease is 0.1389483. This means that the probability of a
40-year-old woman having a heart disease is 0.1389483 times smaller than the
probability of a 40-year-old woman not having a heart disease.</p>
<p><span class="math display">\[
\begin{align}
log(\frac{\pi_i}{1 - \pi_i}) &amp;= -1.973653 \\
  &amp;\leftrightarrow \frac{\pi_i}{1 - \pi_i} = exp(-1.973653) \\
  &amp;\leftrightarrow \frac{\pi_i}{1 - \pi_i} = 0.1389483
\end{align}
\]</span></p>
<p>The estimated odds of a 40-year-old woman having a heart disease can be used to
estimate the probability of such a person having a heart disease.</p>
<p><span class="math display">\[
\begin{align}
log(\frac{\pi_i}{1 - \pi_i})
  &amp;\leftrightarrow \pi_i = \frac{exp(-1.973653)}{1 + exp(-1.973653)} \\
  &amp;\leftrightarrow \pi_i = \frac{0.1389483}{1 + 0.1389483} \\
  &amp;\leftrightarrow \pi_i = \frac{0.1389483}{1.1389483} \\
  &amp;\leftrightarrow \pi_i = 0.121997
\end{align}
\]</span></p>
<p>Assume person <span class="math inline">\(j\)</span> is a 40-year-old man. We can now also calculate the estimated
odds of having a heart disease.</p>
<p><span class="math display">\[
\begin{align}
log(\frac{\pi_j}{1 - \pi_j})
  &amp;= -4.634893 + 0.066531 \cdot 40 + 1.641195 \cdot 1 \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = exp(-4.634893 + 0.066531 \cdot 40 + 1.641195) \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = exp(-4.634893 + 0.066531 \cdot 40) \cdot exp(1.641195) \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = 0.1389483 \cdot 5.161334 \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = 0.7171586
\end{align}
\]</span></p>
<p>From this, we can also see the following:</p>
<p><span class="math display">\[
\begin{align}
log(\frac{\pi_j}{1 - \pi_j})
  &amp;= -4.634893 + 0.066531 \cdot 40 + 1.641195 \cdot 1 \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = exp(-4.634893 + 0.066531 \cdot 40 + 1.641195) \\
  &amp;\leftrightarrow \frac{\pi_j}{1 - \pi_j} = exp(-4.634893 + 0.066531 \cdot 40) \cdot exp(1.641195) \\
  &amp;\leftrightarrow exp(1.641195) = \frac{\frac{\pi_j}{1 - \pi_j}}{exp(-4.634893 + 0.066531 \cdot 40)} \\
  &amp;\leftrightarrow exp(1.641195) = \frac{\frac{\pi_j}{1 - \pi_j}}{\frac{\pi_i}{1 - \pi_i}}
\end{align}
\]</span></p>
<p>In other words, the estimate for <span class="math inline">\(\beta_2\)</span> can be exponentiated to obtain an
odds ratio, and more specifically the odds ratio of the odds of a 40-year-old
man having a heart disease vs. a 40-year-old woman having a heart disease.</p>
</div>
<div id="maximum-likelihood-estimation" class="section level3 hasAnchor" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Maximum Likelihood Estimation<a href="logistic-regression.html#maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The model parameters are estimated using the maximum likelihood estimation
framework. We let the random variable <span class="math inline">\(Y\)</span> denote the outcome, with <span class="math inline">\(Y = 1\)</span>
indicating that the event of interest occurred and <span class="math inline">\(Y = 0\)</span> that the event of
interest did not occur. Because the variable <span class="math inline">\(Y\)</span> is a binary variable its
probability distribution can be described using the following probability mass
function:</p>
<p><span class="math display">\[
\mathbb{P} (Y = y) = \pi^{y} \cdot (1 - \pi)^{(1 - y)}
\]</span></p>
<p>with <span class="math inline">\(\pi\)</span> representing the probability of <span class="math inline">\(Y = 1\)</span>. We can verify this:</p>
<p><span class="math display">\[
\mathbb{P} (Y = 1) = \pi^{1} \cdot (1 - \pi)^{(1 - 1)} = \pi \cdot (1 - \pi)^0 = \pi
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mathbb{P} (Y = 0) = \pi^0 \cdot (1 - \pi)^{(1 - 0)} = (1 - \pi)^1 = 1 - \pi
\]</span></p>
<p>This distribution is defined by a single parameter <span class="math inline">\(\pi\)</span>. In the simple
logistic regression model, the probability of the event of interest occurring
<span class="math inline">\(\pi\)</span> is linked to the linear predictor as follows:</p>
<p><span class="math display">\[
\pi_i = \frac{exp(\beta_0 + \beta_1 x_i)}{1 + exp(\beta_0 + \beta_1 x_i)}
\]</span></p>
<p>In other words, we have:</p>
<p><span class="math display">\[
log(\frac{\pi_i}{1 - \pi_i}) = \beta_0 + \beta_1 x_i + \epsilon_i
\]</span></p>
<p>We can now derive the likelihood and log-likelihood function. The likelihood
function is:</p>
<p><span class="math display">\[
\begin{align}
L(\beta)
  &amp;= \prod_{i = 1}^{n} \pi_i^{y_i} (1 - \pi_i)^{(1 - y_i)}
\end{align}
\]</span></p>
<p>The log-likelihood function is:</p>
<p><span class="math display">\[
\begin{align}
l(\beta) = log(L(\beta))
  &amp;= log \left( \prod_{i = 1}^{n} \pi_i^{y_i} (1 - \pi_i)^{(1 - y_i)} \right) \\
  &amp;= \sum_{i = 1}^{n} \left[ log(\pi_i^{y_i} (1 - \pi_i)^{(1 - y_i)}) \right] \\
  &amp;= \sum_{i = 1}^{n} \left[ y_i \cdot log(\pi_i) + (1 - y_i) \cdot log(1 - \pi_i) \right] \\
  &amp;= \sum_{i = 1}^{n} \left[ y_i \cdot log(\pi_i) - y_i \cdot log(1 - \pi_i) + log(1 - \pi_i) \right] \\
  &amp;= \sum_{i = 1}^{n} \left[ y_i \cdot log(\frac{\pi_i}{1 - \pi_i}) + log(1 - \pi_i) \right]
\end{align}
\]</span></p>
<p>We can derive the following:</p>
<p><span class="math display">\[
\begin{align}
1 - \pi
  &amp;= 1 - \frac{exp(\beta_0 + \beta_1 x_i)}{1 + exp(\beta_0 + \beta_1 x_i)} \\
  &amp;= \frac{1 + exp(\beta_0 + \beta_1 x_i)}{1 + exp(\beta_0 + \beta_1 x_i)} - \frac{exp(\beta_0 + \beta_1 x_i)}{1 + exp(\beta_0 + \beta_1 x_i)} \\
  &amp;= \frac{1}{1 + exp(\beta_0 + \beta_1 x_i)} \\
  &amp;= (1 + exp(\beta_0 + \beta_1 x_i))^{-1}
\end{align}
\]</span></p>
<p>This means the last expression for the log-likelihood can be simplified:</p>
<p><span class="math display">\[
\begin{align}
l(\beta) = log(L(\beta))
  &amp;= \sum_{i = 1}^{n} \left[ y_i \cdot log(\frac{\pi_i}{1 - \pi_i}) + log(1 - \pi_i) \right] \\
  &amp;= \sum_{i = 1}^{n} \bigg[ y_i \cdot (\beta_0 + \beta_1 x_i) - log(1 + exp(\beta_0 + \beta_1 x_i)) \bigg]
\end{align}
\]</span></p>
<p>The maximum likelihood estimates are those values for the model parameters that
minimize the log-likelihood. We can manually look for these maximum likelihood
estimates.</p>
</div>
</div>
<div id="conditional-logistic-regression" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Conditional Logistic Regression<a href="logistic-regression.html#conditional-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we explore <strong>conditional</strong> logistic regression. Conditional
logistic regression allows us to not have to estimate nuisance parameters. We
will illustrate this with an example.</p>
<p>Suppose we have a dataset comprising data on 20 patients distributed across two
hospitals (with 10 patients each). For each patient, we know what hospital they
were admitted to, their age at the time of hospital admission, and if they
survived their hospital stay.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="logistic-regression.html#cb24-1" tabindex="-1"></a><span class="co"># Create the dataset</span></span>
<span id="cb24-2"><a href="logistic-regression.html#cb24-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb24-3"><a href="logistic-regression.html#cb24-3" tabindex="-1"></a></span>
<span id="cb24-4"><a href="logistic-regression.html#cb24-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb24-5"><a href="logistic-regression.html#cb24-5" tabindex="-1"></a>  <span class="at">i =</span> <span class="dv">1</span><span class="dt">L</span><span class="sc">:</span><span class="dv">20</span><span class="dt">L</span>,</span>
<span id="cb24-6"><a href="logistic-regression.html#cb24-6" tabindex="-1"></a>  <span class="at">hospital =</span> <span class="fu">factor</span>(<span class="at">x =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>), <span class="at">each =</span> <span class="dv">10</span>), <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)),</span>
<span id="cb24-7"><a href="logistic-regression.html#cb24-7" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">c</span>(<span class="dv">65</span>, <span class="dv">70</span>, <span class="dv">75</span>, <span class="dv">60</span>, <span class="dv">68</span>, <span class="dv">72</span>, <span class="dv">80</span>, <span class="dv">78</span>, <span class="dv">85</span>, <span class="dv">76</span>, <span class="dv">55</span>, <span class="dv">60</span>, <span class="dv">65</span>, <span class="dv">70</span>, <span class="dv">75</span>, <span class="dv">80</span>, <span class="dv">85</span>, <span class="dv">90</span>, <span class="dv">72</span>, <span class="dv">78</span>),</span>
<span id="cb24-8"><a href="logistic-regression.html#cb24-8" tabindex="-1"></a>  <span class="at">Y =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb24-9"><a href="logistic-regression.html#cb24-9" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 4
##        i hospital   age     Y
##    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1 A           65     1
##  2     2 A           70     0
##  3     3 A           75     1
##  4     4 A           60     0
##  5     5 A           68     1
##  6     6 A           72     0
##  7     7 A           80     0
##  8     8 A           78     0
##  9     9 A           85     0
## 10    10 A           76     0
## 11    11 B           55     1
## 12    12 B           60     1
## 13    13 B           65     1
## 14    14 B           70     0
## 15    15 B           75     1
## 16    16 B           80     1
## 17    17 B           85     0
## 18    18 B           90     1
## 19    19 B           72     0
## 20    20 B           78     1</code></pre>
<div id="definition" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Definition<a href="logistic-regression.html#definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(Y_i\)</span> denote the outcome for patient <span class="math inline">\(i\)</span>, with <span class="math inline">\(Y_i = 1\)</span> if patient <span class="math inline">\(i\)</span> died
and <span class="math inline">\(Y_i = 0\)</span> otherwise. Let <span class="math inline">\(X_i\)</span> denote the age of patient <span class="math inline">\(i\)</span> at the time of
hospital admission. Let <span class="math inline">\(Z_i\)</span> denote the hospital at which patient <span class="math inline">\(i\)</span> was
admitted, with <span class="math inline">\(Z_i = 0\)</span> if patient <span class="math inline">\(i\)</span> was admitted to hospital A and <span class="math inline">\(Z_i = 1\)</span>
otherwise. We can now calculate the probability of patient <span class="math inline">\(i\)</span> dying conditional
on their age and the hospital where they were admitted to as:</p>
<p><span class="math display">\[
\mathbb{P} (Y_i = 1) = \frac{exp(\beta_z \cdot z_i + \beta_x \cdot x_i)}{1 + exp(\beta_z \cdot z_i + \beta_x \cdot x_i)}
\]</span></p>
<p>We know that <span class="math inline">\(\beta_z = 0.24\)</span> and <span class="math inline">\(\beta_x = 0.5\)</span>. We can now calculate the
probability of dying for each patient.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="logistic-regression.html#cb26-1" tabindex="-1"></a><span class="co"># Define the parameters</span></span>
<span id="cb26-2"><a href="logistic-regression.html#cb26-2" tabindex="-1"></a>B_z <span class="ot">&lt;-</span> <span class="fl">1.85</span></span>
<span id="cb26-3"><a href="logistic-regression.html#cb26-3" tabindex="-1"></a>B_x <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb26-4"><a href="logistic-regression.html#cb26-4" tabindex="-1"></a></span>
<span id="cb26-5"><a href="logistic-regression.html#cb26-5" tabindex="-1"></a><span class="co"># Calculate the probability of dying per patient</span></span>
<span id="cb26-6"><a href="logistic-regression.html#cb26-6" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb26-7"><a href="logistic-regression.html#cb26-7" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rowwise</span>() <span class="sc">%&gt;%</span></span>
<span id="cb26-8"><a href="logistic-regression.html#cb26-8" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Z_i =</span> dplyr<span class="sc">::</span><span class="fu">if_else</span>(hospital <span class="sc">==</span> <span class="st">&quot;A&quot;</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">X_i =</span> age) <span class="sc">%&gt;%</span></span>
<span id="cb26-9"><a href="logistic-regression.html#cb26-9" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">P_i =</span> <span class="fu">exp</span>(Z_i <span class="sc">*</span> B_z <span class="sc">+</span> X_i <span class="sc">*</span> B_x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(Z_i <span class="sc">*</span> B_z <span class="sc">+</span> X_i <span class="sc">*</span> B_x)))</span></code></pre></div>
<pre><code>## # A tibble: 20 × 7
## # Rowwise: 
##        i hospital   age     Y   Z_i   X_i   P_i
##    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1 A           65     1     0    65 0.963
##  2     2 A           70     0     0    70 0.971
##  3     3 A           75     1     0    75 0.977
##  4     4 A           60     0     0    60 0.953
##  5     5 A           68     1     0    68 0.968
##  6     6 A           72     0     0    72 0.973
##  7     7 A           80     0     0    80 0.982
##  8     8 A           78     0     0    78 0.980
##  9     9 A           85     0     0    85 0.986
## 10    10 A           76     0     0    76 0.978
## 11    11 B           55     1     1    55 0.990
## 12    12 B           60     1     1    60 0.992
## 13    13 B           65     1     1    65 0.994
## 14    14 B           70     0     1    70 0.995
## 15    15 B           75     1     1    75 0.996
## 16    16 B           80     1     1    80 0.997
## 17    17 B           85     0     1    85 0.998
## 18    18 B           90     1     1    90 0.998
## 19    19 B           72     0     1    72 0.996
## 20    20 B           78     1     1    78 0.997</code></pre>
</div>
<div id="probability" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Probability<a href="logistic-regression.html#probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we outline how to get the probability of a particular outcome
occurring. Suppose we have an ICU with five patients. For each patient, the
presence of diabetes as an underlying comorbidity is recorded. Let <span class="math inline">\(X = 1\)</span>
denote that the patient has diabetes and <span class="math inline">\(X = 0\)</span> otherwise. The probability of
a patient having diabetes depends on several factors, such as age, sex, weight,
lifestyle, genetics, etc, and therefore this probability differs between
patients.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="logistic-regression.html#cb28-1" tabindex="-1"></a><span class="co"># Construct a sample dataset</span></span>
<span id="cb28-2"><a href="logistic-regression.html#cb28-2" tabindex="-1"></a>probs <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">i =</span> <span class="dv">1</span><span class="dt">L</span><span class="sc">:</span><span class="dv">5</span><span class="dt">L</span>, <span class="at">P_i =</span> <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">5</span>))</span></code></pre></div>
<p>In the following table, we see that the probability that patient <span class="math inline">\(i = 1\)</span> has
diabetes is <span class="math inline">\(\mathbb{P} (X_1 = 1) = 0.312\)</span> and for patient <span class="math inline">\(i = 4\)</span> it is
<span class="math inline">\(\mathbb{P} (X_4 = 1) = 0.887\)</span>.</p>
<pre><code>## # A tibble: 5 × 2
##       i   P_i
##   &lt;int&gt; &lt;dbl&gt;
## 1     1 0.312
## 2     2 0.582
## 3     3 0.638
## 4     4 0.887
## 5     5 0.248</code></pre>
<p>We can also calculate the probability of a patient not having diabetes. For
this, the following probability mass function can be used:</p>
<p><span class="math display">\[
f(Y_i = y_1, \pi_i) = \pi_i^{y_i} \cdot (1 - \pi_i)^{(1 - y_i)}
\]</span></p>
<p>We can verify this:</p>
<p><span class="math display">\[
f(Y_4 = 1, \pi_4) = 0.887^1 * (1 - 0.887)^{(1 - 1)} = 0.887
\]</span></p>
<p>and</p>
<p><span class="math display">\[
f(Y_4 = 0, \pi_4) = 0.887^0 * (1 - 0.887)^{(1 - 0)} = 0.113
\]</span></p>
<p>Let the random variable <span class="math inline">\(Y\)</span> denote the number of patients in the ICU having
diabetes. First, we must construct the sample space. One example of a possible
outcome in the sample space is:</p>
<p><span class="math display">\[
(X_1 = 1, X_2 = 0, X_3 = 0, X_4 = 0, X_5 = 1)
\]</span></p>
<p>This possible outcome maps to <span class="math inline">\(Y = 2\)</span>. Another example of a possible outcome:</p>
<p><span class="math display">\[
(X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1)
\]</span></p>
<p>This possible outcome maps to <span class="math inline">\(Y = 3\)</span>. Another example of a possible outcome:</p>
<p><span class="math display">\[
(X_1 = 0, X_2 = 0, X_3 = 1, X_4 = 1, X_5 = 0)
\]</span></p>
<p>This possible outcome maps to <span class="math inline">\(Y = 2\)</span>. Note that we now have two possible
outcomes in the sample space that map to <span class="math inline">\(Y = 2\)</span>. The sample space contains 32
possible outcomes:</p>
<p><span class="math display">\[
{5 \choose 0} + {5 \choose 1} + {5 \choose 2} + {5 \choose 3} + {5 \choose 4} + {5 \choose 5} = 32
\]</span></p>
<p>The following are five examples of the sample space:</p>
<pre><code>## # A tibble: 5 × 5
##   Patient_1 Patient_2 Patient_3 Patient_4 Patient_5
##       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1         0         0         0         0         0
## 2         0         0         0         0         1
## 3         0         0         0         1         0
## 4         0         0         0         1         1
## 5         0         0         1         0         0</code></pre>
<p>We can now calculate the probability of each possible outcome occurring. For the
possible outcome</p>
<p><span class="math display">\[
(X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1)
\]</span></p>
<p>we have</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathbb{P} (Y_1 = 0)
  \cdot \mathbb{P} (Y_2 = 1)
  \cdot \mathbb{P} (Y_3 = 1)
  \cdot \mathbb{P} (Y_4 = 0)
  \cdot \mathbb{P} (Y_5 = 1) \\
  &amp;= \prod_{i = 1}^{5} \bigg[ f(Y_i = y_i, \pi_i) \bigg] \\
  &amp;= f(Y_1 = 0, \pi_1)
    \cdot f(Y_2 = 1, \pi_2)
    \cdot f(Y_3 = 1, \pi_3)
    \cdot f(Y_4 = 0, \pi_4)
    \cdot f(Y_5 = 1, \pi_5) \\
  &amp;= (1 - 0.3121850)
    \cdot 0.5821874
    \cdot 0.6381059
    \cdot (1 - 0.8872664)
    \cdot 0.2481097 \\
  &amp;= 0.007147012
\end{aligned}
\]</span></p>
<p>We can calculate this as follows:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="logistic-regression.html#cb31-1" tabindex="-1"></a><span class="co"># Get the observed outcome</span></span>
<span id="cb31-2"><a href="logistic-regression.html#cb31-2" tabindex="-1"></a>Y_vector <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb31-3"><a href="logistic-regression.html#cb31-3" tabindex="-1"></a></span>
<span id="cb31-4"><a href="logistic-regression.html#cb31-4" tabindex="-1"></a><span class="co"># Calculate the probability</span></span>
<span id="cb31-5"><a href="logistic-regression.html#cb31-5" tabindex="-1"></a>prob_Y <span class="ot">&lt;-</span> <span class="fu">prod</span>(probs<span class="sc">$</span>P_i<span class="sc">^</span>Y_vector <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> probs<span class="sc">$</span>P_i)<span class="sc">^</span>(<span class="dv">1</span> <span class="sc">-</span> Y_vector))</span>
<span id="cb31-6"><a href="logistic-regression.html#cb31-6" tabindex="-1"></a>prob_Y</span></code></pre></div>
<pre><code>## [1] 0.007147012</code></pre>
<p>This is the probability of this possible outcome occurring. This possible
outcome maps to <span class="math inline">\(Y = 3\)</span>. If we want to know <span class="math inline">\(\mathbb{P} (Y = 3)\)</span>, we must sum
the probabilities of every possible outcome that maps to <span class="math inline">\(Y = 3\)</span>. We define the
set of all possible outcomes mapping to <span class="math inline">\(Y = 3\)</span> as <span class="math inline">\(S(t)\)</span> where <span class="math inline">\(t = 3\)</span>:</p>
<p><span class="math display">\[
S(t) = \{ (Y_1 = y_1^*, ..., Y_5 = y_5^*) | \sum_{i = 1}^{5} y_i^* = t \}
\]</span></p>
<p>In the case of <span class="math inline">\(Y = 3\)</span>, <span class="math inline">\(S(3)\)</span> contains ten possible outcomes. We calculate the
probability of <span class="math inline">\(Y = 3\)</span> as follows:</p>
<p><span class="math display">\[
\mathbb{P} (Y = 3) = \sum_{S(3)} \Bigg[ \prod_{i = 1}^{5} \bigg[ f(Y_i = y_i^*, \pi_i) \bigg] \Bigg]
\]</span></p>
<p>We can calculate this as follows:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="logistic-regression.html#cb33-1" tabindex="-1"></a><span class="co"># Get the subset of the sample space that maps to Y = 3</span></span>
<span id="cb33-2"><a href="logistic-regression.html#cb33-2" tabindex="-1"></a>event_space <span class="ot">&lt;-</span> sample_space[<span class="fu">rowSums</span>(sample_space) <span class="sc">==</span> <span class="dv">3</span>,, drop <span class="ot">=</span> F]</span>
<span id="cb33-3"><a href="logistic-regression.html#cb33-3" tabindex="-1"></a></span>
<span id="cb33-4"><a href="logistic-regression.html#cb33-4" tabindex="-1"></a><span class="co"># Calculate the probability</span></span>
<span id="cb33-5"><a href="logistic-regression.html#cb33-5" tabindex="-1"></a>prob_Y <span class="ot">&lt;-</span> <span class="fl">0.0</span></span>
<span id="cb33-6"><a href="logistic-regression.html#cb33-6" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(event_space)) {</span>
<span id="cb33-7"><a href="logistic-regression.html#cb33-7" tabindex="-1"></a>  </span>
<span id="cb33-8"><a href="logistic-regression.html#cb33-8" tabindex="-1"></a>  <span class="co"># Get the observed outcome</span></span>
<span id="cb33-9"><a href="logistic-regression.html#cb33-9" tabindex="-1"></a>  Y_vector <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(event_space[i,, <span class="at">drop =</span> <span class="cn">TRUE</span>])</span>
<span id="cb33-10"><a href="logistic-regression.html#cb33-10" tabindex="-1"></a>  prob_Y <span class="ot">&lt;-</span> prob_Y <span class="sc">+</span> <span class="fu">prod</span>((probs<span class="sc">$</span>P_i)<span class="sc">^</span>Y_vector <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> probs<span class="sc">$</span>P_i)<span class="sc">^</span>(<span class="dv">1</span> <span class="sc">-</span> Y_vector))</span>
<span id="cb33-11"><a href="logistic-regression.html#cb33-11" tabindex="-1"></a>  </span>
<span id="cb33-12"><a href="logistic-regression.html#cb33-12" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## [1] 0.3736777</code></pre>
<p>So, we have <span class="math inline">\(\mathbb{P} (Y = 3) = 0.3736777\)</span>.</p>
<p>As stated earlier, the probability of a patient <span class="math inline">\(i\)</span> having diabetes depends on
several factors, such as sex, age, weight, etc. The probability of a patient <span class="math inline">\(i\)</span>
having diabetes is denoted as <span class="math inline">\(\pi_i = \mathbb{P} (Y_i = 1)\)</span>. This probability
can be derived as follows:</p>
<p><span class="math display">\[
\pi_i = \frac{exp(\alpha + \beta \textbf{X}^{-1})}{1 + exp(\alpha + \beta \textbf{X}^{-1})}
\]</span></p>
<p>We can use this to rewrite the following:</p>
<p><span class="math display">\[
\begin{align}
f(Y_i = y_i, \pi_i)
  &amp;= \pi_i^{y_i} * (1 - \pi_i)^{(1 - y_i)} \\
  &amp;= \frac{exp(y_i \cdot (\alpha + \beta \textbf{X}^{-1}))}{1 + exp(\alpha + \beta \textbf{X}^{-1})}
\end{align}
\]</span></p>
<p>For a particular possible outcome of the sample space, we have:</p>
<p><span class="math display">\[
\begin{align}
\prod_{i = 1}^5 f(Y_i = y_i, \pi_i)
  &amp;= \prod_{i = 1}^5 \frac{exp(y_i \cdot (\alpha + \beta \textbf{X}^{-1}))}{1 + exp(\alpha + \beta \textbf{X}^{-1})} \\
  &amp;= \frac{\prod_{i = 1}^5 exp(y_i \cdot (\alpha + \beta \textbf{X}^{-1}))}{\prod_{i = 1}^5 \big[ 1 + exp(\alpha + \beta \textbf{X}^{-1}) \big]} \\
  &amp;= \frac{\prod_{i = 1}^5 exp(y_i \alpha + y_i \beta \textbf{X}^{-1}))}{\prod_{i = 1}^5 \big[ 1 + exp(\alpha + \beta \textbf{X}^{-1}) \big]} \\
  &amp;= \frac{exp(\sum_{i = 1}^5  \big[ y_i \alpha + y_i \beta \textbf{X}^{-1} \big] )}{\prod_{i = 1}^5 \big[ 1 + exp(\alpha + \beta \textbf{X}^{-1}) \big]} \\
  &amp;= \frac{exp(\sum_{i = 1}^5 y_i \alpha + \sum_{i = 1}^5 y_i \beta \textbf{X}^{-1})}{\prod_{i = 1}^5 \big[ 1 + exp(\alpha + \beta \textbf{X}^{-1}) \big]} \\
  &amp;= \frac{exp(\alpha \sum_{i = 1}^5 y_i + \sum_{i = 1}^5 y_i \beta \textbf{X}^{-1})}{\prod_{i = 1}^5 \big[ 1 + exp(\alpha + \beta \textbf{X}^{-1}) \big]} \\
\end{align}
\]</span></p>
</div>
<div id="conditional-probability" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Conditional Probability<a href="logistic-regression.html#conditional-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can calculate the probability <span class="math inline">\(\mathbb{P} (Y = y)\)</span>. But we can also calculate
the conditional probability of a particular possible outcome given the event
of interest. Suppose we are not interested in the following:</p>
<p><span class="math display">\[
\mathbb{P} (X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1)
\]</span></p>
<p>but in the following:</p>
<p><span class="math display">\[
\mathbb{P} (X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1 | Y = 3)
\]</span></p>
<p>We can calculate this as follows:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1 | Y = 3)
&amp;= \frac{\mathbb{P} (X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1)}{\mathbb{P} (Y = 3)} \\
&amp;= \frac{\mathbb{P} (X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0, X_5 = 1)}{\sum_{S(3)} \Bigg[ \prod_{i = 1}^{5} \bigg[ f(Y_i = y_i^*, \pi_i) \bigg] \Bigg]}
\end{align}
\]</span></p>
</div>
<div id="probability-1" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Probability<a href="logistic-regression.html#probability-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before continuing our explanation on conditional logistic regression, we focus
on how to calculate the probability of a particular outcome occurring. For this,
we first focus on a single hospital, i.e., we focus on hospital <strong>A</strong>.</p>
<pre><code>## # A tibble: 10 × 7
## # Rowwise: 
##        i hospital   age     Y   Z_i   X_i   P_i
##    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1 A           65     1     0    65 0.963
##  2     2 A           70     0     0    70 0.971
##  3     3 A           75     1     0    75 0.977
##  4     4 A           60     0     0    60 0.953
##  5     5 A           68     1     0    68 0.968
##  6     6 A           72     0     0    72 0.973
##  7     7 A           80     0     0    80 0.982
##  8     8 A           78     0     0    78 0.980
##  9     9 A           85     0     0    85 0.986
## 10    10 A           76     0     0    76 0.978</code></pre>
<p>Hospital <strong>A</strong> has 10 patients, and there are two possible outcomes for each
patient, dead or alive. The outcome of interest <span class="math inline">\(Y\)</span> is the number of patients
that have died during their hospital stay. The data frame above shows one
possible outcome for hospital <strong>A</strong> where two out of ten patients died during
their hospital stay. More specifically, patients <span class="math inline">\(i = 1\)</span> and <span class="math inline">\(i = 5\)</span> died. This
is only one of a few possible outcomes where two patients die. There are, in
fact, <span class="math inline">\(10 \choose 2 = 45\)</span> possible outcomes in which two patients die. The total
number of possible outcomes is shown below, where <span class="math inline">\(Y\)</span> denotes how many patients
died during their hospital stay and <span class="math inline">\(SS\)</span> denotes how many of the possible
outcomes in the sample space map to <span class="math inline">\(Y\)</span>.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="logistic-regression.html#cb36-1" tabindex="-1"></a>tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb36-2"><a href="logistic-regression.html#cb36-2" tabindex="-1"></a>  <span class="at">Y =</span> <span class="dv">0</span><span class="dt">L</span><span class="sc">:</span><span class="dv">10</span><span class="dt">L</span>,</span>
<span id="cb36-3"><a href="logistic-regression.html#cb36-3" tabindex="-1"></a>  <span class="at">SS =</span> <span class="fu">choose</span>(<span class="dv">10</span>, Y)</span>
<span id="cb36-4"><a href="logistic-regression.html#cb36-4" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 11 × 2
##        Y    SS
##    &lt;int&gt; &lt;dbl&gt;
##  1     0     1
##  2     1    10
##  3     2    45
##  4     3   120
##  5     4   210
##  6     5   252
##  7     6   210
##  8     7   120
##  9     8    45
## 10     9    10
## 11    10     1</code></pre>
<p>So, with <span class="math inline">\(Y = 9\)</span>, there are 9 possible outcomes mapping to this outcome. We can
define the set of possible outcomes mapping to <span class="math inline">\(Y = 9\)</span> as follows:</p>
<p><span class="math display">\[
S(t) = \{ (Y_1 = y_1^*, ..., Y_{10} = y_{10}^*) | \sum_{i = 1}^{10} y_i^* = t \}
\]</span></p>
<p>with <span class="math inline">\(t = y\)</span>. In this case, <span class="math inline">\(S(t)\)</span> denotes the set of possible outcomes mapping
to <span class="math inline">\(Y = t\)</span>. If we know the probability of each patient <span class="math inline">\(i\)</span> dying, then, for each
possible outcome we can calculate the probability of that outcome occurring as
follows:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (\textbf{Y} = \textbf{y})
  = \mathbb{P} (Y_1 = y_1, ..., Y_{10} = y_{10})
  &amp;= \mathbb{P} (Y_1 = y_1) \times \text{ ... } \times\mathbb{P} (Y_{10} = y_{10})
\end{align}
\]</span></p>
<p>If we want to know the probability of <span class="math inline">\(Y = 3\)</span>, then we must first obtain the
probabilities for each possible outcome in <span class="math inline">\(S(3)\)</span> and sum these up. So we have:</p>
<p><span class="math display">\[
\sum_{S(t)} \mathbb{P} (\textbf{Y} = \textbf{y} | t = 3)
\]</span></p>
<p>We can calculate this:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="logistic-regression.html#cb38-1" tabindex="-1"></a><span class="co"># Construct the sample space</span></span>
<span id="cb38-2"><a href="logistic-regression.html#cb38-2" tabindex="-1"></a>sample_space <span class="ot">&lt;-</span> gtools<span class="sc">::</span><span class="fu">permutations</span>(</span>
<span id="cb38-3"><a href="logistic-regression.html#cb38-3" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">2</span>, <span class="at">r =</span> <span class="dv">10</span>,</span>
<span id="cb38-4"><a href="logistic-regression.html#cb38-4" tabindex="-1"></a>  <span class="at">v =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">repeats.allowed =</span> <span class="cn">TRUE</span></span>
<span id="cb38-5"><a href="logistic-regression.html#cb38-5" tabindex="-1"></a>)</span>
<span id="cb38-6"><a href="logistic-regression.html#cb38-6" tabindex="-1"></a>sample_space <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">as_tibble</span>(sample_space, <span class="at">.name_repair =</span> <span class="st">&quot;minimal&quot;</span>)</span>
<span id="cb38-7"><a href="logistic-regression.html#cb38-7" tabindex="-1"></a></span>
<span id="cb38-8"><a href="logistic-regression.html#cb38-8" tabindex="-1"></a><span class="co"># Get the subset of possible outcomes corresponding to Y = 3</span></span>
<span id="cb38-9"><a href="logistic-regression.html#cb38-9" tabindex="-1"></a>event_space <span class="ot">&lt;-</span> sample_space[<span class="fu">rowSums</span>(sample_space) <span class="sc">==</span> <span class="dv">3</span>,, drop <span class="ot">=</span> F]</span>
<span id="cb38-10"><a href="logistic-regression.html#cb38-10" tabindex="-1"></a></span>
<span id="cb38-11"><a href="logistic-regression.html#cb38-11" tabindex="-1"></a><span class="co"># Calculate the probability of Y = 3</span></span>
<span id="cb38-12"><a href="logistic-regression.html#cb38-12" tabindex="-1"></a>prob_Y <span class="ot">&lt;-</span> <span class="fl">0.0</span></span>
<span id="cb38-13"><a href="logistic-regression.html#cb38-13" tabindex="-1"></a>probs <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(hospital <span class="sc">==</span> <span class="st">&quot;A&quot;</span>) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">pull</span>(P_i)</span>
<span id="cb38-14"><a href="logistic-regression.html#cb38-14" tabindex="-1"></a></span>
<span id="cb38-15"><a href="logistic-regression.html#cb38-15" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="dt">L</span><span class="sc">:</span><span class="fu">nrow</span>(event_space)) {</span>
<span id="cb38-16"><a href="logistic-regression.html#cb38-16" tabindex="-1"></a>  </span>
<span id="cb38-17"><a href="logistic-regression.html#cb38-17" tabindex="-1"></a>  <span class="co"># Get the outcomes for each patient corresponding to Y = 3</span></span>
<span id="cb38-18"><a href="logistic-regression.html#cb38-18" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(event_space[i,, <span class="at">drop =</span> <span class="cn">TRUE</span>])</span>
<span id="cb38-19"><a href="logistic-regression.html#cb38-19" tabindex="-1"></a>  </span>
<span id="cb38-20"><a href="logistic-regression.html#cb38-20" tabindex="-1"></a>  <span class="co"># Calculate the probability of this particular outcome occurring</span></span>
<span id="cb38-21"><a href="logistic-regression.html#cb38-21" tabindex="-1"></a>  prob_Y <span class="ot">&lt;-</span> prob_Y <span class="sc">+</span> <span class="fu">prod</span>(probs<span class="sc">^</span>Y <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> probs)<span class="sc">^</span>(<span class="dv">1</span> <span class="sc">-</span> Y))</span>
<span id="cb38-22"><a href="logistic-regression.html#cb38-22" tabindex="-1"></a>  </span>
<span id="cb38-23"><a href="logistic-regression.html#cb38-23" tabindex="-1"></a>}</span>
<span id="cb38-24"><a href="logistic-regression.html#cb38-24" tabindex="-1"></a></span>
<span id="cb38-25"><a href="logistic-regression.html#cb38-25" tabindex="-1"></a>prob_Y</span></code></pre></div>
<pre><code>## [1] 8.732308e-10</code></pre>
<p><span class="math display">\[
\mathbb{P} (\textbf{Y} = \textbf{y}) = \mathbb{P} (Y_1 = y_1, Y_2 = y_2, ..., Y_n = Y_n)
  &amp;= \frac{exp(\beta_z \cdot z_i + \beta_x \cdot x_i)}{1 + exp(\beta_z \cdot z_i + \beta_x \cdot x_i)}
\]</span></p>
<p>Now, suppose we are only interested in <span class="math inline">\(\beta_x\)</span> and not in <span class="math inline">\(\beta_z\)</span>, the
latter being a nuisance parameter. We would like to eliminate <span class="math inline">\(\beta_z\)</span> from
the estimation. We can do this by conditioning the likelihood function. This
results in an estimate only for age <span class="math inline">\(X_i\)</span>. Within each hospital, we want to
calculate the probability of obtaining a particular outcome, e.g., 3 out of
10 patients died.</p>
<p>Let us look at our two hospitals and the outcomes. We can then see that 3 out of
10 patients died in hospital A and 7 out of 10 patients in hospital B.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="logistic-regression.html#cb40-1" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>hospital, df<span class="sc">$</span>Y)</span></code></pre></div>
<pre><code>##    
##     0 1
##   A 7 3
##   B 3 7</code></pre>
<p>We can calculate the probability of this outcome for each hospital. To calculate
the probability of a single patient dying, we have:</p>
<p><span class="math display">\[
\mathbb{P} (Y_i = 1) = \frac{exp(\beta_z z_i + \beta_x x_i)}{1 + exp(\beta_z z_i + \beta_x x_i)}
\]</span></p>
<p>Or if we do not know what the outcome is but we want to calculate the
probability of that outcome:</p>
<p><span class="math display">\[
\mathbb{P} (Y_i = y_i) = \frac{exp(y_i \cdot (\beta_z z_i + \beta_x x_i))}{1 + exp(\beta_z z_i + \beta_x x_i)}
\]</span></p>
<p>We have ten patients per hospital. If we want to calculate the probability of a
particular outcome occurring, we have:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (Y_1 = y_1, ..., Y_n = y_n)
  &amp;= \prod_{i = 1}^{n} \frac{exp(y_i \cdot (\beta_z z_i + \beta_x x_i))}{1 + exp(\beta_z z_i + \beta_x x_i)} \\
  &amp;= \frac{\prod_{i = 1}^{n} exp(y_i \cdot (\beta_z z_i + \beta_x x_i))}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]} \\
  &amp;= \frac{\prod_{i = 1}^{n} exp(y_i \beta_z z_i + y_i \beta_x x_i))}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]} \\
  &amp;= \frac{exp(\sum_{i = 1}^{n} y_i \beta_z z_i + \sum_{i = 1}^{n} y_i \beta_x x_i))}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]} \\
  &amp;= \frac{exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i))}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]}
\end{align}
\]</span></p>
<p>We can now calculate the probability of the outcome <span class="math inline">\(Y_1 = 1\)</span>, <span class="math inline">\(Y_3 = 1\)</span>, and
<span class="math inline">\(Y_8 = 1\)</span> in hospital A occurring. Note that we specify three particular
patients that have died. But if we are only interested in 3 out of 10 patients
dying in hospital A. In that case, there are <span class="math inline">\({10 \choose 3} = 120\)</span> outcomes of
interest. First, we define this set of 120 outcomes:</p>
<p><span class="math display">\[
S(t) = \{ (Y_1 = y_1, Y_2, = y_2, ..., Y_n = y_n) | \sum_{i = 1}^{n} y_i = t \}
\]</span></p>
<p>To calculate the probability of <span class="math inline">\(S(t)\)</span> occurring, we can calculate this as
follows:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (S(t))
  &amp;= \sum_{S(t)} \mathbb{P} (Y_1 = y_i, ..., Y_n = y_n) \\
  &amp;= \sum_{S(t)} [\frac{exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i))}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]}] \\
  &amp;= \frac{1}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]} \cdot \sum_{S(t)} [exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i))]
\end{align}
\]</span></p>
<p>We can now calculate the conditional probability of the outcome <span class="math inline">\(Y_1 = 1\)</span>,
<span class="math inline">\(Y_3 = 1\)</span>, and <span class="math inline">\(Y_8\)</span> conditional on that 3 out of 10 patients died in hospital A.</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (Y_1 = 0, Y_2 = 0, Y_3 = 1, ..., Y_{10} = 0 | \sum_{i} y_i = 10)
  &amp;= \frac{\mathbb{P} (Y_1 = y_1, ..., Y_{10} = y_{10})}{\mathbb{P} (S(t = 3))} \\
  &amp;= \frac{\frac{exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i)}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]}}{\frac{1}{\prod_{i = 1}^{n} [1 + exp(\beta_z z_i + \beta_x x_i)]} \cdot \sum_{S(t)} [exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i))]} \\
  &amp;= \frac{exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i)]}
\end{align}
\]</span></p>
<p>Because we look at each hospital individually, we know what the value is for
<span class="math inline">\(z_i\)</span> for each patient. If we look at hospital B, we know that <span class="math inline">\(z_i = 1\)</span> for
<span class="math inline">\(i = 1, ..., 10\)</span>. In that case, we have:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{P} (Y_1 = 0, Y_2 = 0, Y_3 = 1, ..., Y_{10} = 0 | \sum_{i} y_i = 10)
  &amp;= \frac{exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_z \sum_{i = 1}^{n} y_i z_i + \beta_x \sum_{i = 1}^{n} y_i x_i)]} \\
  &amp;= \frac{exp(\beta_z \sum_{i = 1}^{n} y_i + \beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_z \sum_{i = 1}^{n} y_i + \beta_x \sum_{i = 1}^{n} y_i x_i)]} \\
  &amp;= \frac{exp(\beta_z t + \beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_z t + \beta_x \sum_{i = 1}^{n} y_i x_i)]} \\
  &amp;= \frac{exp(\beta_z t) exp(\beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_z t) exp(\beta_x \sum_{i = 1}^{n} y_i x_i)]} \\
  &amp;= \frac{exp(\beta_z t) exp(\beta_x \sum_{i = 1}^{n} y_i x_i)}{exp(\beta_z t) \sum_{S(t)} [exp(\beta_x \sum_{i = 1}^{n} y_i x_i)]} \\
  &amp;= \frac{exp(\beta_x \sum_{i = 1}^{n} y_i x_i)}{\sum_{S(t)} [exp(\beta_x \sum_{i = 1}^{n} y_i x_i)]}
\end{align}
\]</span></p>
<p>This is the conditional probability. We can use this to determine the
conditional likelihood and log-likelihood, in which we do not have to estimate
the nuisance parameter <span class="math inline">\(\beta_z\)</span>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-models-and-deviance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="missingness.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/03-logistic-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
